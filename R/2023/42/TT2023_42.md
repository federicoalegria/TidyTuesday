---
author: "Federico Alegría"
editor: visual
format:
  html:
    embed-resources: true
title: "Taylor Swift"
theme: journal # https://quarto.org/docs/output-formats/html-themes.html
toc: true
---

```{r}
#| code-overflow: wrap
#| echo: false
#| warning: false

# Libraries
pacman::p_load(
  easystats,
  ggridges,
  ggstatsplot,
  ggthemes,
  janitor,
  patchwork,
  skimr,
  tidyverse
)

# DATA ----

taylor_album_songs <-
  readr::read_csv(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_album_songs.csv'
  ) |> 
  clean_names()

# CLEAN ----

# Transform ----

# album names
taylor_album_songs <-
  taylor_album_songs |>
  mutate(album_name = gsub("\\(Taylor's Version\\)", "", album_name) |>
           str_trim() |>
           str_to_title())

# duration milliseconds to duration seconds
taylor_album_songs <- 
  taylor_album_songs |> 
  mutate(duration = (duration_ms)/1000)
```

Amidst [The Eras Tour Film](https://www.tstheerastourfilm.com/) release, Tidy Tuesday's `2023_42`, came with three [major datasets](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md) from which I picked `taylor_album_songs`. This dataset was pulled from the Spotify API for all songs on Taylor's official studio albums; this excludes singles released separately from an album and non-Taylor-owned albums that have a Taylor-owned alternative. On this observational bulletin, I report Spotify measures valence across Taylor's songs!

## Valence

Valence is a measure of the musical positiveness conveyed by a track, [ranging from 0.0 to 1.0](http://student.elon.edu/slichtenstein/SpotifyAnalysis/). Tracks with high valence sound more positive, happy, cheerful, and euphoric, while tracks with low valence sound more negative, sad, depressed, and angry. Spotify calculates valence based on various musical elements, such as [harmony, chord progression, and timbre](https://community.spotify.com/t5/Spotify-for-Developers/Valence-as-a-measure-of-happiness/td-p/4385221).

The following box plots display `valence`'s distribution for each album. Box plots help us to visualise the following summary statistics: (a) median, (b) the interquartile range, (c) minimum and maximum values and (d) all the quirky outliers falling away from the observable whiskers.

```{r}
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| warning: false

taylor_album_songs |>
  mutate(album_name = reorder(album_name, valence)) |>
  ggplot(aes(x = album_name,
             y = valence)) +
  geom_boxplot(aes(fill = album_name), alpha = 0.7) +
  scale_fill_manual(
    values = c(
      "#400303",
      "#731803",
      "#967862",
      "#b38468",
      "#c7c5b6",
      "#160e10",
      "#421e18",
      "#d37f55",
      "#85796d",
      "#e0d9d7"
    )
  ) +
  geom_jitter(color = "#1D4737", alpha = 0.4) +
  labs(
    title = "Taylor Swift's valence by albums",
    subtitle = "box plots based on data pulled from Spotify's Web API with spotifyr",
    caption = "{tidytuesday 2023∙42}
    https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md",
    x = "Valence",
    y = "Album Name"
  ) +
  theme_solarized() +
  theme(legend.position = "none") +
  coord_flip()
```

Alternatively, the following Ridge-line plot helps seeing `valence`'s distribution in a useful fashion for visualising changes across Taylor Swift's albums.

```{r}
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| warning: false

taylor_album_songs |>
  mutate(album_name = reorder(album_name, valence)) |>
  ggplot(aes(x = valence, y = album_name)) +
  geom_density_ridges(aes(fill = album_name), alpha = 0.7) +
  scale_fill_manual(
    values = c(
      "#400303",
      "#731803",
      "#967862",
      "#b38468",
      "#c7c5b6",
      "#160e10",
      "#421e18",
      "#d37f55",
      "#85796d",
      "#e0d9d7"
    )
  ) +
  labs(
    title = "Taylor Swift's valence by albums",
    subtitle = "ridge plots based on data pulled from Spotify's Web API with spotifyr",
    caption = "{tidytuesday 2023∙42}
    https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md",
    x = "Valence",
    y = "Album Name",
    fill = "Album Name"
  ) +
  theme_solarized() +
  theme(legend.position = "none")
```

## Detecting strong predictors

In order to understand valence in a proper way, some tests on all double variables spanning from zero to one were made:

```{r}
#| code-fold: false
#| code-overflow: wrap 
#| echo: true
#| output: true
#| warning: false

lm(
  valence ~ danceability + energy + mode + speechiness + acousticness + instrumentalness + liveness,
  data = taylor_album_songs
) |> 
  summary()
```

Given the prior call to `lm()`, the most significant variables affecting `valence` are checked for assumptions of a linear regression model to be met.

```{r}
#| code-fold: false
#| code-overflow: wrap
#| echo: true
#| output: true
#| warning: false

lm(
  valence ~ energy + danceability + acousticness,
  data = taylor_album_songs
) |> 
  summary()
  
taylor_album_songs |>
  select(valence, energy, danceability, acousticness) |> # ordered from smallest to largest 
  correlation(redundant = TRUE) |> 
  summary()
```

```{r}
#| code-fold: false
#| code-overflow: wrap
#| echo: true
#| output: false
#| warning: false

lm(
  valence ~ energy + danceability + acousticness,
  data = taylor_album_songs
) |> 
  check_model()
```

After consulting Google's Bard on [20231021Z2315](https://g.co/bard/share/e59b45b94b4f), it's accepted the following from the `lm()` function from the {stats} package in R:

> The output of the lm() function in R gives important information about a linear regression model:
>
> -   Coefficients: The coefficients table shows the estimated coefficients for each of the predictor variables. The intercept is the estimated value of the response variable when all of the predictor variables are equal to zero. The coefficients for the predictor variables show the estimated change in the response variable for a one-unit increase in the predictor variable, holding all other predictor variables constant.
> -   P-values: The p-values for the coefficients indicate the probability of obtaining a coefficient as extreme or more extreme than the one observed, assuming the null hypothesis is true. The null hypothesis is that the coefficient is equal to zero. A p-value less than 0.05 is generally considered to be statistically significant, which means that we reject the null hypothesis in favour of the alternative hypothesis that the coefficient is not equal to zero.
>
> **In the `valence ~ energy + danceability + acousticness` case, all of the p-values are less than 0.05, which means that all of the predictor variables are significantly associated with the response variable.**
>
> -   R-squared: The R-squared value is a measure of the goodness of fit of the model. It ranges from 0 to 1, with higher values indicating a better fit. An R-squared value of 0.3863 means that the model explains 38.63% of the variation in the response variable.
> -   Adjusted R-squared: The adjusted R-squared value is a penalized version of the R-squared value that takes into account the number of predictor variables in the model. It is a more accurate measure of the goodness of fit of the model when there are multiple predictor variables.
> -   F-statistic: The F-statistic is a test of the overall significance of the model. It tests the null hypothesis that all of the predictor variables are equal to zero. A p-value less than 0.05 is generally considered to be statistically significant, which means that we reject the null hypothesis in favour of the alternative hypothesis that at least one of the predictor variables is not equal to zero.
>
> **In this case, the p-value for the F-statistic is less than 0.05, which means that the model is statistically significant.**

![](figures/fig-03.png)

| ***Assumptions***              | ***Interpretation***                                                                                                                  |
|------------------------------------|------------------------------------|
| **Posterior Predictive Check** | Model-predicted lines resemble the observed data line, which is a good sign.                                                          |
| **Linearity**                  | Reference line is slightly curved, which suggests that there may be some non-linearity in the relationship between the variables.     |
| **Homogeneity of Variance**    | reference line is slightly curved, which suggests that there may be some heteroscedasticity (non-constant variance) in the residuals. |
| **Influential Observations**   | No clearly influential observations.                                                                                                  |
| **Collinearity**               | All of the VIF values are less than 10, so there is no evidence of collinearity.                                                      |
| **Normality of Residuals**     | Since the dots are slightly scattered, residuals may not be perfectly normally distributed.                                           |

Overall, the diagnostics suggest the model is a reasonable fit to the data. However, there are a few potential issues with the model, such as non-linearity in the relationship between the variables and heteroskedasticity in the residuals. It is important to consider these issues when interpreting the results of the model. Some further tests for normality is a safe choice:

```{r}
#| code-fold: false
#| code-overflow: wrap
#| echo: true
#| output: true
#| warning: false

shapiro.test(taylor_album_songs$valence)
shapiro.test(taylor_album_songs$energy)
shapiro.test(taylor_album_songs$danceability)
shapiro.test(taylor_album_songs$acousticness)
```

> The Shapiro-Wilk test is a statistical test for normality. It tests the null hypothesis that the data is normally distributed. The p-value is the probability of obtaining a test statistic as extreme or more extreme than the one observed, assuming the null hypothesis is true. A p-value less than 0.05 is generally considered to be statistically significant, which means that we reject the null hypothesis in favour of the alternative hypothesis that the data is not normally distributed.

Based on the results of the Shapiro-Wilk tests, the following can be conclude:

-   The `valence` and `energy` variables are not normally distributed (p-values \< 0.05).
-   The `danceability` variable may be normally distributed (p-value \> 0.05).
-   The `acousticness` variable is not normally distributed (p-value \< 0.05).

It is important to note that the Shapiro-Wilk test is more sensitive to deviations from normality in smaller sample sizes. Therefore, it is possible that the `danceability` variable is not normally distributed, but the Shapiro-Wilk test failed to detect the deviation from normality due to the relatively large sample size (n = 284).

```{r}
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| output: true
#| warning: false

lm(
  valence ~ energy + danceability + acousticness,
  data = taylor_album_songs
) |> 
  report()
```

## Model

Given the automated report (Makowski et al., 2023), the following mutation will be performed:

```{mermaid}
flowchart LR
A(energy) --- B(Amasement)
C(danceability) --- B
D(acousticness) --- B
B --> E(Valence)
```

From fitting the linear models and according to the mathematical formula of the [linear regression](http://www.sthda.com/english/articles/40-regression-analysis/165-linear-regression-essentials-in-r/):

$$
y = b0 + b1 * x1 + b2 * x2 + ... + bn * xn
$$ {#eq-01}

```{r}
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| warning: false

taylor_album_songs |>
  mutate(amasement = (energy + danceability + acousticness) / 3) |>
  ggplot(aes(x = valence,
             y = amasement)) +
  geom_point(aes(colour = album_name, size = duration_ms)) +
  scale_color_manual(
    values = c(
      "#400303",
      "#731803",
      "#967862",
      "#b38468",
      "#c7c5b6",
      "#160e10",
      "#421e18",
      "#d37f55",
      "#85796d",
      "#e0d9d7"
    )
  ) +
  labs(
    title = "Predictor model for valence in Taylor Swift songs",
    subtitle = "analysis based on data from Spotify's Web API with {spotifyr}",
    caption = "{tidytuesday 2023∙42}
    https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md",
    x = "Valence",
    y = "Amasement",
    fill = "Album Name",
    colour = "Album Name"
  ) +
  geom_smooth(colour = "#1D4737", method = "lm") +
  theme_solarized() +
  guides(size = "none")
```

$$
Valence = -0.39636 + (0.77939 * energy) + (0.48194 * danceability) + (0.21171 * acousticness)
$$ {#eq-02}

## TL;DR

The results of the linear regression model suggest that `energy`, `danceability`, and `acousticness` are all significantly associated with Spotify's `valence` measurement of Taylor Swift's album songs.

The model explains 38.63% of the variation in the valence of all her **amazing** songs! Specifically, the estimated coefficients for `energy`, `danceability`, and `acousticness` are all positive. This means that songs with higher `amasement` are more likely to have higher `valence` scores. e.g. a one-unit increase in energy is estimated to increase the `valence` of a song by 0.77939 units, holding all other predictor variables constant.

Last but not least, consider listening to [this](https://www.youtube.com/watch?v=FvVnP8G6ITs) 🦄

## Disclaimer

It is important to note that this is just an observational study, so no formal conclusiones should be made that observable `amasement` cause changes in `valence`. However, the results of the study suggest that these factors are important to consider when trying to predict the valence of Taylor Swift's album songs.

## Further

What explains the unattended 61.37%?

## References

-   Makowski, D., Lüdecke, D., Patil, I., Thériault, R., Ben-Shachar, M.S., & Wiernik, B.M. (2023). Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption. CRAN. Available from https://easystats.github.io/report/ doi: .
